{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv, json, os, numbers, pandas, re, scipy, scipy.sparse, shutil\n",
    "import subprocess, sys, threading, time, urllib2\n",
    "\n",
    "def exec_ipynb(filename_or_url):\n",
    "    nb = (urllib2.urlopen(filename_or_url) if re.match(r'https?:', filename_or_url) else open(filename_or_url)).read()\n",
    "    jsonNb = json.loads(nb)\n",
    "    #check for the modified formatting of Jupyter Notebook v4\n",
    "    if(jsonNb['nbformat'] == 4):\n",
    "        exec '\\n'.join([''.join(cell['source']) for cell in jsonNb['cells'] if cell['cell_type'] == 'code']) in globals()\n",
    "    else:\n",
    "        exec '\\n'.join([''.join(cell['input']) for cell in jsonNb['worksheets'][0]['cells'] if cell['cell_type'] == 'code']) in globals()\n",
    "\n",
    "exec_ipynb('timelapse-utilities.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pandas.options.display.max_colwidth = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download ACS2015 File Templates for 5-year and 1-year data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = 'https://www2.census.gov/programs-surveys/acs/summary_file/2015/data/2015_1yr_Summary_FileTemplates.zip'\n",
    "dest = 'capture/ACS2015_1year/2015_1yr_Summary_FileTemplates.zip'\n",
    "download_file(src, dest)\n",
    "templates = unzip_file(dest)\n",
    "\n",
    "src = 'https://www2.census.gov/programs-surveys/acs/summary_file/2015/data/2015_5yr_Summary_FileTemplates.zip'\n",
    "dest = 'capture/ACS2015_5year/2015_5yr_Summary_FileTemplates.zip'\n",
    "download_file(src, dest)\n",
    "templates = unzip_file(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls -l capture/ACS2015_1year/2015_1yr_Summary_FileTemplates/Templates | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download ACS2015 5-year data (tract and block group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.0) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.97 Safari/537.11\" --header=\"Referer: http://xmodulo.com/\" https://www2.census.gov/programs-surveys/acs/summary_file/2015/data/5_year_entire_sf/Tracts_Block_Groups_Only.tar.gz\n",
    "\n",
    "!mkdir -p capture/ACS2005_5year\n",
    "!mv Tracts_Block_Groups_Only.tar.gz capture/ACS2005_5year\n",
    "\n",
    "!cd capture/ACS2005_5year; tar xvfz Tracts_Block_Groups_Only.tar.gz >/dev/null\n",
    "\n",
    "!wget --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.0) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.97 Safari/537.11\" https://www2.census.gov/programs-surveys/acs/summary_file/2015/data/5_year_entire_sf/2015_ACS_Geography_Files.zip\n",
    "\n",
    "!mv 2015_ACS_Geography_Files.zip capture/ACS2005_5year\n",
    "\n",
    "unzip_file('capture/ACS2005_5year/2015_ACS_Geography_Files.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_acs2015_5year_template(seqno):\n",
    "    path = 'capture/ACS2015_5year/2015_5yr_Summary_FileTemplates/2015_5yr_Templates/Seq%d.xls' % seqno\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    return pandas.read_excel(path)\n",
    "\n",
    "# Combine template header and data into pandas frame\n",
    "def read_acs2015_year_data(state, seqno):\n",
    "    header = read_acs2015_5year_template(seqno)\n",
    "    data = pandas.read_csv('capture/ACS2015_5year/group2/e20155%s%04d000.txt' % (state, seqno),\n",
    "                            index_col=False,\n",
    "                            dtype={'FILEID':numpy.str,\n",
    "                                   'FILETYPE':numpy.str,\n",
    "                                   'STUSAB':numpy.str,\n",
    "                                   'CHARITER':numpy.str,\n",
    "                                   'SEQUENCE':numpy.str,\n",
    "                                   'LOGRECNO':numpy.str},\n",
    "                            header=None,\n",
    "                            names=header.columns.values)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = 'acs2015_5year_tract2010'\n",
    "column_dir = 'columncache'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write ACS2015 5-year description.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_path = column_dir + '/' + dataset + '/description.html'\n",
    "force_regenerate = True\n",
    "\n",
    "if os.path.exists(description_path) and not force_regenerate:\n",
    "    print '{description_path} already exists, skipping'.format(**locals())\n",
    "else:\n",
    "    table_rows = []\n",
    "\n",
    "    for seqno in range(1, 1000):\n",
    "        template = read_acs2015_5year_template(seqno)\n",
    "        if template is None:\n",
    "            break\n",
    "        for col in range(6, template.shape[1]):\n",
    "            colname = template.columns.values[col]\n",
    "            description = template.iloc[0,col]\n",
    "            description = description.replace(':', '')\n",
    "            description = re.sub(r'\\s*%\\s*', ' &mdash; ', description)\n",
    "            table_rows.append(u'<tr><td>{dataset}.{colname}</td><td>{description}</td></tr>\\n'.format(**locals()))\n",
    "\n",
    "    html = '<table>' + ''.join(table_rows) + '</table>'\n",
    "\n",
    "    open(description_path, 'w').write(html.encode('utf8'))\n",
    "    print 'Wrote %d column names and descriptions to %s' % (len(table_rows), description_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create ACS2015 block-level population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read 2010 block geoids and 2010 block populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_populations = numpy.load('columncache/census2010_block2010/p001001.numpy')\n",
    "print 'block_populations has', sum(block_populations), 'total people'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_geoids_2010 = [row[0] for row in query_psql(\"SELECT geoid2010 FROM sf1_2010_block_p001 order by blockidx2010\")]\n",
    "block_geoids_2010 = json.load(open('block_geoids_2010.json'))\n",
    "print 'There are', len(block_geoids_2010), 'blocks'\n",
    "\n",
    "assert(len(block_geoids_2010) + 1 == len(block_populations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute 2010 population by tract and block indices from tract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_populations = {}\n",
    "tract_block_indexes = {}\n",
    "\n",
    "for block_index_minus_one, block_geoid in enumerate(block_geoids_2010):\n",
    "    block_index = block_index_minus_one + 1\n",
    "    tract_name = block_geoid[0:11]\n",
    "    if tract_name not in tract_populations:\n",
    "        tract_populations[tract_name] = 0\n",
    "        tract_block_indexes[tract_name] = []\n",
    "    tract_populations[tract_name] += block_populations[block_index]\n",
    "    tract_block_indexes[tract_name].append(block_index)\n",
    "\n",
    "print 'There are', len(tract_populations), 'tracts'\n",
    "print 'tract_populations has', sum(tract_populations.values()), 'people'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map tract identifiers to LOGRECNO using geography file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_to_logrecno = {}\n",
    "\n",
    "def compute_tract_to_logrecno(state):\n",
    "    geography = pandas.read_csv('capture/ACS2015_5year/2015_ACS_Geography_Files/g20155{state}.csv'.format(**locals()),\n",
    "                                dtype=numpy.str,\n",
    "                                index_col=False,\n",
    "                                header=None,\n",
    "                                keep_default_na=False,\n",
    "                                na_values=[])\n",
    "\n",
    "    nrows = geography.shape[0]\n",
    "    print 'State {state} has {nrows} geography rows'.format(**locals())\n",
    "    \n",
    "    ntracts = 0\n",
    "    tract_to_logrecno[state] = {}\n",
    "    \n",
    "    for r in range(0, geography.shape[0]):\n",
    "        aggregation_level = geography.iloc[r, 2]\n",
    "        if aggregation_level == '140': # census tract\n",
    "            tract_identifier = geography.iloc[r, 48][7:]\n",
    "            logrecno = geography.iloc[r, 4]\n",
    "            tract_to_logrecno[state][tract_identifier] = logrecno\n",
    "    \n",
    "    print 'Found %d tracts for state %s' % (len(tract_to_logrecno[state]), state)\n",
    "\n",
    "for state in state_names:\n",
    "    compute_tract_to_logrecno(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate and write columns for data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: can we do this with a data frame then write out columns?\n",
    "\n",
    "def interpolate_acs_file(state, seq):\n",
    "    print 'Reading %s:%d' % (state, seq)\n",
    "    data = read_acs2015_year_data(state, seq)\n",
    "\n",
    "    print 'Mapping locrecno to row'\n",
    "    logrecnos = data['LOGRECNO']\n",
    "\n",
    "    logrecno_to_row = {}\n",
    "\n",
    "    for r, logrecno in enumerate(logrecnos):\n",
    "        logrecno_to_row[logrecno] = r\n",
    "    \n",
    "    col_names = data.columns.values[6:]\n",
    "    print 'Iterating across %d columns' % len(col_names)\n",
    "    for col_name in col_names:\n",
    "        input_col = data[col_name]\n",
    "        output_col_path = column_dir + '/' + dataset + '/' + col_name + '.float32'\n",
    "        if os.path.exists(output_col_path):\n",
    "            print '%s already exists, skipping' % output_col_path\n",
    "            continue\n",
    "\n",
    "        output_col = numpy.zeros(block_populations.size, dtype=numpy.float32)\n",
    "\n",
    "        for tract in sorted(tract_to_logrecno[state].keys()):\n",
    "            input_pop = input_col[logrecno_to_row[tract_to_logrecno[state][tract]]]\n",
    "            if not isinstance(input_pop, numbers.Number):\n",
    "                if input_pop == '.':\n",
    "                    input_pop = 0\n",
    "                else:\n",
    "                    try:\n",
    "                        input_pop = float(input_pop)\n",
    "                    except:\n",
    "                        print 'That population is'\n",
    "                        print input_pop\n",
    "                        print type(input_pop)\n",
    "                        print '>%s<' % input_pop\n",
    "                        input_pop = 0\n",
    "            if not tract in tract_block_indexes:\n",
    "                print 'missing tract {tract} from tract_block_indexes'.format(**locals())\n",
    "            else:\n",
    "                for block_index in tract_block_indexes[tract]:\n",
    "                    if block_populations[block_index]:\n",
    "                        output_col[block_index] = input_pop * float(block_populations[block_index]) / tract_populations[tract]\n",
    "            \n",
    "        output_col.tofile(output_col_path + '.tmp')\n",
    "        os.rename(output_col_path + '.tmp', output_col_path)\n",
    "        print 'Created %s' % output_col_path\n",
    "\n",
    "for seq in range(97, 2000):\n",
    "    interpolate_acs_file('pa', seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: can we do this with a data frame then write out columns?\n",
    "\n",
    "def interpolate_acs_file(seq):\n",
    "    output_cols = {}\n",
    "    missing_tracts = {}\n",
    "    for state in state_names:\n",
    "        data = read_acs2015_year_data(state, seq)\n",
    "    \n",
    "        logrecnos = data['LOGRECNO']\n",
    "\n",
    "        logrecno_to_row = {}\n",
    "\n",
    "        col_names = data.columns.values[6:]\n",
    "        print '%s:%d has %d columns' % (state, seq, len(col_names))\n",
    "        assert len(col_names) < 500   # sanity check to avoid demanding too much RAM on hal15\n",
    "\n",
    "        for r, logrecno in enumerate(logrecnos):\n",
    "            logrecno_to_row[logrecno] = r\n",
    "    \n",
    "        for col_name in col_names:\n",
    "            input_col = data[col_name]\n",
    "                \n",
    "            if not col_name in output_cols:\n",
    "                output_cols[col_name] = numpy.zeros(block_populations.size, dtype=numpy.float32)\n",
    "            output_col = output_cols[col_name]\n",
    "\n",
    "            for tract in sorted(tract_to_logrecno[state].keys()):\n",
    "                input_pop = input_col[logrecno_to_row[tract_to_logrecno[state][tract]]]\n",
    "                if not isinstance(input_pop, numbers.Number):\n",
    "                    if input_pop == '.':\n",
    "                        input_pop = 0\n",
    "                    else:\n",
    "                        try:\n",
    "                            input_pop = float(input_pop)\n",
    "                        except:\n",
    "                            print 'That population is'\n",
    "                            print input_pop\n",
    "                            print type(input_pop)\n",
    "                            print '>%s<' % input_pop\n",
    "                            input_pop = 0\n",
    "                            \n",
    "                            \n",
    "                if not tract in tract_block_indexes:\n",
    "                    missing_tracts[tract] = True\n",
    "                else:\n",
    "                    for block_index in tract_block_indexes[tract]:\n",
    "                        if block_populations[block_index]:\n",
    "                            output_col[block_index] = input_pop * float(block_populations[block_index]) / tract_populations[tract]\n",
    "            \n",
    "    print 'Missing tracts: %s' % (sorted(missing_tracts.keys()))\n",
    "\n",
    "    for col_name in sorted(output_cols.keys()):\n",
    "        output_col_path = column_dir + '/' + dataset + '/' + col_name + '.float32'\n",
    "        output_cols[col_name].tofile(output_col_path + '.tmp')\n",
    "        os.rename(output_col_path + '.tmp', output_col_path)\n",
    "        print 'Created %s with sum %f' % (output_col_path, output_cols[col_name].sum())\n",
    "    \n",
    "        \n",
    "for seq in range(1, 1000):\n",
    "    interpolate_acs_file(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tract_block_indexes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l columncache/acs2015_5year_tract2010/B08006_002.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=numpy.memmap('columncache/acs2015_5year_tract2010/B08006_002.float32', dtype=numpy.float32, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
