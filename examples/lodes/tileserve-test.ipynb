{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set default_psql_database to census2010\n",
      "gcc -pthread -shared -rdynamic -fno-strict-aliasing -g -DNDEBUG -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/rsargent/anaconda2/include/python2.7 -L/home/rsargent/anaconda2/lib/python2.7/site-packages -lpython2.7 /tmp/tmpHtjm6N.c -o /tmp/tmp1JiYwu-000000.so\n",
      "404\n",
      "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2 Final//EN\">\n",
      "<title>404 Not Found</title>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL was not found on the server.  If you entered the URL manually please check your spelling and try again.</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv, json, os, pandas, re, scipy, scipy.sparse, shutil\n",
    "import subprocess, sys, threading, time, urllib2\n",
    "\n",
    "def exec_ipynb(filename_or_url):\n",
    "    nb = (urllib2.urlopen(filename_or_url) if re.match(r'https?:', filename_or_url) else open(filename_or_url)).read()\n",
    "    jsonNb = json.loads(nb)\n",
    "    #check for the modified formatting of Jupyter Notebook v4\n",
    "    if(jsonNb['nbformat'] == 4):\n",
    "        exec '\\n'.join([''.join(cell['source']) for cell in jsonNb['cells'] if cell['cell_type'] == 'code']) in globals()\n",
    "    else:\n",
    "        exec '\\n'.join([''.join(cell['input']) for cell in jsonNb['worksheets'][0]['cells'] if cell['cell_type'] == 'code']) in globals()\n",
    "\n",
    "exec(open('tileserve.py').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Removing the least recent takes O(N) time;  could be make more efficient if needed for larger dicts\n",
    "\n",
    "class LruDict:\n",
    "    def __init__(self, max_entries):\n",
    "        self.max_entries = max_entries\n",
    "        self.entries = {}\n",
    "        self.usecount = 0\n",
    "    \n",
    "    def has(self, key):\n",
    "        return key in self.entries\n",
    "    \n",
    "    def get(self, key):\n",
    "        print 'getting %s' % key\n",
    "        self.use(key)\n",
    "        return self.entries[key]['data']\n",
    "    \n",
    "    def use(self, key):\n",
    "        self.usecount += 1\n",
    "        self.entries[key]['lastuse'] = self.usecount\n",
    "\n",
    "    def insert(self, key, val):\n",
    "        print 'inserting %s' % key\n",
    "        self.entries[key] = {'data':val}\n",
    "        self.use(key)\n",
    "        if len(self.entries) > self.max_entries:\n",
    "            lru_key, lru_val = None, None\n",
    "            for key, val in self.entries.iteritems():\n",
    "                if not lru_val or val['lastuse'] < lru_val['lastuse']:\n",
    "                    lru_key, lru_val = key, val\n",
    "            if lru_val:\n",
    "                del self.entries[lru_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_cache = LruDict(200) # max entries\n",
    "\n",
    "def map_as_array(path):\n",
    "    return numpy.memmap(path, dtype=numpy.float32, mode='r')\n",
    "\n",
    "def load_column(dataset, column):\n",
    "    cache_key = '{dataset}.{column}'.format(**locals())\n",
    "    if column_cache.has(cache_key):\n",
    "        return column_cache.get(cache_key)\n",
    "    dir = '{cache_dir}/{dataset}'.format(cache_dir=cache_dir, **locals())\n",
    "    if not os.path.exists(dir):\n",
    "        msg = 'Dataset named \"{dataset}\" not found.<br><br><a href=\"{dataroot}\">List valid datasets</a>'.format(dataroot=dataroot(), **locals())\n",
    "        raise InvalidUsage(msg)\n",
    "    cache_filename_prefix = dir + '/' + column\n",
    "    if os.path.exists(cache_filename_prefix + '.float32'):\n",
    "        data = map_as_array(cache_filename_prefix + '.float32')\n",
    "    elif os.path.exists(cache_filename_prefix + '.numpy'):\n",
    "        data = numpy.load(open(cache_filename_prefix + '.numpy'))\n",
    "    else:\n",
    "        msg = 'Column named \"{column}\" in dataset \"{dataset}\" not found.<br><br><a href=\"{dataroot}/{dataset}\">List valid columns from {dataset}</a>'.format(dataroot=dataroot(), **locals())\n",
    "        raise InvalidUsage(msg)\n",
    "\n",
    "    column_cache.insert(cache_key, data)\n",
    "    return data\n",
    "\n",
    "testnow = False\n",
    "\n",
    "if testnow:\n",
    "    print load_column('census1990_block2010', 'P0010001').sum()\n",
    "    print load_column('acs2015_5year_tract2010', 'B01001_001').sum()\n",
    "    print load_column('census1990_block2010', 'P0010001').sum()\n",
    "    print load_column('acs2015_5year_tract2010', 'B01001_001').sum()\n",
    "    print load_column('census1990_block2010', 'P0010001').sum()\n",
    "    print load_column('acs2015_5year_tract2010', 'B01001_001').sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting acs2015_5year_tract2010.B01001_001\n",
      "getting acs2015_5year_tract2010.B01001_001\n",
      "0.0\n",
      "getting census1990_block2010.P0010001\n",
      "getting acs2015_5year_tract2010.B01001_001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "memmap([  0.        ,  81.        ,   0.        , ...,   1.77455461,\n",
       "         0.        ,   0.        ], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expression_cache = LruDict(100) # \n",
    "\n",
    "def eval_layer_column(expr):\n",
    "    try:\n",
    "        return eval_(ast.parse(expr, mode='eval').body)\n",
    "    except SyntaxError,e:\n",
    "        raise InvalidUsage('<pre>' + traceback.format_exc(0) + '</pre>')\n",
    "\n",
    "print eval_layer_column('acs2015_5year_tract2010.B01001_001 - acs2015_5year_tract2010.B01001_001').sum()\n",
    "eval_layer_column('census1990_block2010.P0010001 - acs2015_5year_tract2010.B01001_001')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acs2015_5year_tract2010.B01001_001': {'data': memmap([ 0.,  0.,  0., ...,  0.,  0.,  0.], dtype=float32),\n",
       "  'lastuse': 2}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_cache.entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
