{
 "metadata": {
  "name": "",
  "signature": "sha256:8df11f0152803b0d302d9aa2518daffb6867cd80cf6368e45534fd2e3cab63b8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import array, datetime, glob, json, math, os, re, time, urllib2\n",
      "\n",
      "def init_capture(*args):\n",
      "    for path in args:\n",
      "        if not os.path.exists(path):\n",
      "            os.makedirs(path)\n",
      "\n",
      "def download_file(url, filename):\n",
      "    try:\n",
      "        f = urllib2.urlopen(url)\n",
      "        with open(filename, \"wb\") as local_file:\n",
      "            local_file.write(f.read())\n",
      "    except:\n",
      "        print \"Failed to download %s\" % url\n",
      "\n",
      "def format_viirs_url(url,date):\n",
      "    return url % date\n",
      "\n",
      "def LonLatToWebMercator(lon, lat):\n",
      "    x = (lon + 180.0) * 256.0 / 360.0\n",
      "    y = 128.0 - math.log(math.tan((lat + 90.0) * math.pi / 360.0)) * 128.0 / math.pi\n",
      "    return [x, y]\n",
      "\n",
      "def WebMercatorToLonLat(x,y):\n",
      "    lat = math.atan(math.exp((128.0 - y) * math.pi / 128.0)) * 360.0 / math.pi - 90.0\n",
      "    lon = x * 360.0 / 256.0 - 180.0\n",
      "    return [lon, lat]\n",
      "\n",
      "# alt in meters\n",
      "def LatLonToECEF(lat, lon, elv = 0):\n",
      "    lat = lat * (math.pi/180)\n",
      "    lon = lon * (math.pi/180)\n",
      "    radius = (6.371e6 + elv) / 6.371e6\n",
      "    x = -radius * math.cos(lat) * math.sin(lon)\n",
      "    y = radius * math.sin(lat)\n",
      "    z = -radius * math.cos(lat)*math.cos(lon)\n",
      "    return [x,y,z]\n",
      "\n",
      "def extract_feature_data(feature,convert=None):\n",
      "    data = []\n",
      "    lon = feature['geometry']['coordinates'][0]\n",
      "    lat = feature['geometry']['coordinates'][1]\n",
      "    elv = feature['geometry']['coordinates'][1]\n",
      "    \n",
      "    if convert == \"ECEF\":\n",
      "        xyz = LatLonToECEF(lat, lon, elv)\n",
      "        data.append(xyz[0])\n",
      "        data.append(xyz[1])\n",
      "        data.append(xyz[2])\n",
      "    elif convert == \"WM\":\n",
      "        xy = LonLatToWebMercator(lon,lat)\n",
      "        data.append(xy[0])\n",
      "        data.append(xy[1])\n",
      "    else:\n",
      "        data.append(lat)\n",
      "        data.append(lon)\n",
      "        \n",
      "    date_re = re.compile('\\d{4}/\\d{2}/\\d{2} \\d{2}:\\d{2}:\\d{2}')\n",
      "    date_match = date_re.search(feature['properties']['Description'])\n",
      "    \n",
      "    temp_re = re.compile('(\\d+.\\d+) deg. K')\n",
      "    temp_match = temp_re.search(feature['properties']['Description'])\n",
      "\n",
      "    if date_match != None and temp_match != None:\n",
      "        date = date_match.group(0)\n",
      "        temp = temp_match.group(1)\n",
      "    else:\n",
      "        return []\n",
      "        \n",
      "    if float(temp) == 1810.0 or float(temp) <= 500 or float(temp) >= 3000:\n",
      "        return []\n",
      "    else:\n",
      "        data.append(time.mktime(time.strptime(date, \"%Y/%m/%d %H:%M:%S\")))\n",
      "        data.append(float(temp))\n",
      "        return data\n",
      "\n",
      "def extract_float_data(filename, convert = None):\n",
      "    data = []\n",
      "    obj = json.loads(open(filename).read())    \n",
      "    for feature in obj['features']:\n",
      "        geometry = feature['geometry']\n",
      "        if geometry['type'] == 'Point':\n",
      "            vals = extract_feature_data(feature, convert)\n",
      "            if vals != []:\n",
      "                data += vals\n",
      "        else :\n",
      "            print geometry['type']\n",
      "    return data\n",
      "        \n",
      "def download_files(**kwargs):\n",
      "    end_date = kwargs['end_date']\n",
      "    start_date = kwargs['start_date']\n",
      "    url = kwargs['url']\n",
      "    delta = end_date - start_date\n",
      "    for i in range(delta.days + 1):\n",
      "        url = format_viirs_url(kmz_url,(start_date + datetime.timedelta(days=i)).strftime(\"%Y%m%d\"))\n",
      "        filename = kmz_dir + os.path.basename(url)\n",
      "        download_file(url, filename)\n",
      "\n",
      "def kmz_to_geojson(**kwargs):\n",
      "    kmz_dir = kwargs['kmz_dir']\n",
      "    kml_dir = kwargs['kml_dir']\n",
      "    geojson_dir = kwargs['geojson_dir']\n",
      "    \n",
      "    command = 'ren %s\"*.kmz\" \"#1.zip\"' % kmz_dir\n",
      "    !$command\n",
      "\n",
      "    command = \"for file in %s*.zip; do unzip $file *.kml -d %s; done\" % (kmz_dir, kml_dir)\n",
      "    !$command\n",
      "\n",
      "    command = \"for file in %s*.kml; do ogr2ogr -f GeoJSON %s`basename $file`.json $file; done\" % (kml_dir, geojson_dir)\n",
      "    !$command\n",
      "\n",
      "def geojson_to_bin(**kwargs):\n",
      "    geojson_dir = kwargs['geojson_dir']\n",
      "    outfile = kwargs['outfile']\n",
      "    convert = kwargs['convert'] if kwargs.has_key('convert') else None\n",
      "    data = []\n",
      "    for filename in glob.glob('%s*'%geojson_dir):\n",
      "        data += extract_float_data(filename, convert)\n",
      "    print \"Total points: %d\" % (len(data)/4)\n",
      "    array.array('f', data).tofile(open(outfile, 'w')) \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Download Prerun V2.1 (CLASS) corrected KMZ</h1>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kmz_dir = \"capture/v21/kmz/\"\n",
      "kml_dir = \"capture/v21/kml/\"\n",
      "geojson_dir = \"capture/v21/geojson/\"\n",
      "init_capture(kmz_dir, kml_dir, geojson_dir)\n",
      "\n",
      "kmz_url = 'http://mapserver.ngdc.noaa.gov/viirs/nightfire_v21/corrected/VNF_npp_d%s_v21_atm.kmz'\n",
      "\n",
      "start_date = datetime.date(2014, 7, 30)\n",
      "end_date = datetime.date(2015,4,1)\n",
      "\n",
      "download_files(url=kmz_url, start_date=start_date, end_date=end_date)\n",
      "\n",
      "kmz_to_geojson(kmz_dir=kmz_dir, kml_dir=kml_dir, geojson_dir=geojson_dir)\n",
      "\n",
      "geojson_to_bin(geojson_dir=geojson_dir,outfile='createlab-viirs-uncorrected.bin')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Download Prerun V2.1 (CLASS) non-corrected KMZ</h1>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kmz_dir = \"capture/nightfire_v21/non_corrected/kmz/\"\n",
      "kml_dir = \"capture/nightfire_v21/non_corrected/kml/\"\n",
      "geojson_dir = \"capture/nightfire_v21/non_corrected/geojson/\"\n",
      "\n",
      "init_capture(kmz_dir, kml_dir, geojson_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kmz_url = 'http://mapserver.ngdc.noaa.gov/viirs/nightfire_v21/non_corrected/VNF_npp_d%s_noaa_v21.kmz'\n",
      "start_date = datetime.date(2014, 3, 14)\n",
      "end_date = datetime.date(2015,4,3)\n",
      "download_files(url=kmz_url, start_date=start_date, end_date=end_date)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kmz_to_geojson(kmz_dir=kmz_dir, kml_dir=kml_dir, geojson_dir=geojson_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "geojson_to_bin(geojson_dir=geojson_dir,outfile='createlab-viirs-uncorrected.bin', convert=\"WM\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Convert lat/lon to ECEF</h1>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "geojson_to_bin(geojson_dir=geojson_dir,outfile='createlab-viirs-ecef-uncorrected-1.bin', convert=\"ECEF\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib\n",
      "import urllib2\n",
      "\n",
      "key = \"\"\n",
      "# Geocode a street address using Google's geocoding API\n",
      "# Returns {'lat': latitude, 'lng': longitude} on success\n",
      "# Returns False if not found\n",
      "# Raises exception if a problem occurs (such as running out of quota)\n",
      "#\n",
      "# Note:  Google's geolocation service is limited to around 2500 geolocations per day.  If you receive\n",
      "# an error that you've run out of quota, you'll need to wait a day, or change your IP address.\n",
      "#\n",
      "\n",
      "def elevate(locations):\n",
      "    # Perform API call to maps.googleapis.com, which will return address in JSON format\n",
      "    url = 'https://maps.googleapis.com/maps/api/elevation/json?parameters?%s' % urllib.urlencode({'locations': locations, 'sensor': 'false', 'key': key})\n",
      "    try:\n",
      "        elevate = json.loads(urllib2.urlopen(url).read())\n",
      "    except:\n",
      "        msg = 'When trying to elevate locations %s by reading url %s' % (locations, url)\n",
      "        raise Exception(msg)\n",
      "    if elevate['status'] == 'OK' and elevate['results']:\n",
      "        # Success!  Return the results\n",
      "        return elevate['results']\n",
      "    elif elevate['status'] <> 'ZERO_RESULTS':\n",
      "        # Something failed (maybe out of quota?).  Raise an exception.\n",
      "        msg = 'When trying to elevate locations %s by reading url %s, received a status != OK: %s' % (locations, url, elevate['status'])\n",
      "        print msg\n",
      "        raise Exception(msg)\n",
      "    else:\n",
      "        # No results for this location.  Return false.\n",
      "        return False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def elevate_geojson(data, start = 0):\n",
      "    locations = ''\n",
      "    end = len(data[\"features\"])\n",
      "    for i in range(start,end):\n",
      "        geom = data[\"features\"][i][\"geometry\"][\"coordinates\"]\n",
      "        locations += \"%s,%s|\" % (str(geom[1]), str(geom[0])) # GeoJSON is LON,LAT Google API is LAT,LON\n",
      "        if len(locations) > 1000:\n",
      "            break\n",
      "    locations = locations[:len(locations)-1]\n",
      "    elevated_locations = elevate(locations)\n",
      "    return [elevated_locations, i]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the len(data)\n",
      "# Open a GeoJSON and\n",
      "def add_elevation_to_geojson(i_fn, o_fn):\n",
      "    f = open(i_fn)\n",
      "    data = json.load(f)\n",
      "    f.close()\n",
      "\n",
      "    elevated_data= []\n",
      "    end = len(data['features'])\n",
      "    i = 0\n",
      "    count = 0\n",
      "    while i < end:\n",
      "        result = elevate_geojson(data, i)\n",
      "        elevated_data += result[0]\n",
      "        i = result[1] + 1\n",
      "        count += 1\n",
      "        if count % 10 == 0:\n",
      "            # Checkpoint:  every ten, save all locations to disk\n",
      "            #write_students(geocoded_students)\n",
      "            time.sleep(1) # 10 requests per second limit\n",
      "    print \"%s total API calls \" % count\n",
      "    if len(elevated_data) != len(data[\"features\"]):\n",
      "        print \"WARNING. Feature count mismatch.\" \n",
      "\n",
      "    for i in range(0, len(data[\"features\"])):\n",
      "        data[\"features\"][i][\"geometry\"][\"coordinates\"][2] = elevated_data[i][\"elevation\"]\n",
      "\n",
      "    with open(o_fn, 'w') as outfile:\n",
      "       json.dump(data, outfile, indent=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "april = [\n",
      "\"VNF_npp_d20150401_noaa_v21.kml\",\n",
      "\"VNF_npp_d20150402_noaa_v21.kml\",\n",
      "\"VNF_npp_d20150403_noaa_v21.kml\"\n",
      "]\n",
      "\n",
      "for day in april:\n",
      "    i_fn = \"capture/nightfire_v21/non_corrected/geojson/%s.json\" % day\n",
      "    o_fn = \"capture/nightfire_v21/non_corrected/geojson/%s.geojson\" % day\n",
      "    add_elevation_to_geojson(i_fn, o_fn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "geojson_to_bin(geojson_dir='elevated-geojson/',outfile='createlab-viirs-ecef.bin', convert=\"ECEF\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}