{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import json\n",
      "\n",
      "#\n",
      "# Functions to load and save scraped McDonalds locations to/from this local JSON file:\n",
      "#\n",
      "\n",
      "locations_path = os.path.expanduser('~/projects/mcdonalds/mcdonalds_locations.json')\n",
      "\n",
      "\n",
      "def read_or_create_locations():\n",
      "    try:\n",
      "        locations = json.load(open(locations_path))\n",
      "        print 'Read %d locations from %s' % (len(locations), locations_path)\n",
      "    except StandardError:\n",
      "        locations = []\n",
      "        print '%s does not exist; creating' % locations_path\n",
      "        write_locations(locations)\n",
      "    return locations\n",
      "\n",
      "def write_locations(locations):\n",
      "    try:\n",
      "        os.makedirs(os.path.dirname(locations_path))\n",
      "    except StandardError:\n",
      "        pass\n",
      "    json.dump(locations, open(locations_path + '.tmp', 'w'), indent=2)\n",
      "    os.rename(locations_path + '.tmp', locations_path)\n",
      "    print 'Wrote %d locations to %s' % (len(locations), locations_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read previously scraped locations, if any\n",
      "\n",
      "locations = read_or_create_locations()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Read 5030 locations from /Users/rsargent/projects/mcdonalds/mcdonalds_locations.json\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib2\n",
      "\n",
      "# Geocode a street address using Google's geocoding API\n",
      "# Returns {'lat': latitude, 'lng': longitude} on success\n",
      "# Returns False if not found\n",
      "# Raises exception if a problem occurs (such as running out of quota)\n",
      "#\n",
      "# Note:  Google's geolocation service is limited to around 2500 geolocations per day.  If you receive\n",
      "# an error that you've run out of quota, you'll need to wait a day, or change your IP address.  If you\n",
      "# don't want to wait a day, here are some ways to change your IP address:\n",
      "#    - If you're on a laptop, move to a different wireless network\n",
      "#    - Find an HTTP proxy at http://www.hidemyass.com/proxy-list and switch to that proxy with this python command:\n",
      "#      urllib2.install_opener(urllib2.build_opener(urllib2.ProxyHandler({'http': '168.63.167.183'})))\n",
      "#    - Utitlize a VPN service (e.g. Hide My Ass's \"Pro VPN\" account, which costs $)\n",
      "\n",
      "def geocode(address):\n",
      "    url = 'http://maps.googleapis.com/maps/api/geocode/json?%s' % urllib.urlencode({'address': address, 'sensor': 'false'})\n",
      "    geocode = json.loads(urllib2.urlopen(url).read())\n",
      "    if geocode['status'] == 'OK' and geocode['results']:\n",
      "        return geocode['results'][0]['geometry']['location']\n",
      "    elif geocode['status'] <> 'ZERO_RESULTS':\n",
      "        msg = 'When trying to geocode address %s by reading url %s, received a status != OK: %s' % (address, url, geocode['status'])\n",
      "        print msg\n",
      "        raise Exception(msg)\n",
      "    else:\n",
      "        return False\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib\n",
      "import urllib2\n",
      "from scrapy.selector import Selector\n",
      "\n",
      "# Scrape an individual McDonalds store #\n",
      "# Returns {'store_number': store_number, 'address': address, 'lat': latitude, 'lng': longitude} on success\n",
      "# If McDonalds website doesn't show a store by that number, return False\n",
      "# If geolocation fails, will return only 'store_number' and 'address'\n",
      "#\n",
      "# Things to watch out for:\n",
      "#\n",
      "# 1) If you see \"No module named scrapy.selector\", you'll need to install the scrapy library.\n",
      "#   I installed on my Mac from the commandline with \"pip install scrapy\"\n",
      "#\n",
      "# 2) If you see errors about zope.interface, try updating zope.interface to a newer version like so:\n",
      "#    \"pip install --update zope.interface\"\n",
      "#    and then restart the kernel (Kernel/Restart, at the top of the notebook, above).\n",
      "#\n",
      "\n",
      "def scrape_store(store_number):\n",
      "    # Oddly, www.mcdonalds.com's map application redirects to www.mc<statename>.com to show store details.\n",
      "    # But, lucky for us, any of the states sites seem to work for all store #s.  So let's go with PA for no particular reason.\n",
      "    url = \"http://www.mcpennsylvania.com/%d\" % store_number\n",
      "    \n",
      "    print \"Trying to fetch store# %d from %s\" % (store_number, url)\n",
      "    html = urllib2.urlopen(url).read()\n",
      "    print \"  Read %d bytes\" % len(html)\n",
      "    \n",
      "    # Using Scrapy, build an XPath selector to parse the received HTML\n",
      "    selector = Selector(text = html)\n",
      "    \n",
      "    # The street address is buried in the <li> tag whose class contains the word \"address\" (usually address_3 but\n",
      "    # sometimes address_1 and maybe others).\n",
      "    # Inside that <li>, find all the <h3> tags, extract text from them, and then join together with newlines in-between.\n",
      "    address = '\\n'.join(selector.xpath('//li[contains(@class, \"address\")]/h3/text()').extract())\n",
      "    \n",
      "    if address:\n",
      "        location = {'store_number': store_number, 'address': address}\n",
      "        print '  Address is %s' % address.replace('\\n', '|')\n",
      "        latlng = geocode(address)\n",
      "        if latlng:\n",
      "            print '  Geocoded to %s' % latlng\n",
      "            location['lat'] = latlng['lat']\n",
      "            location['lng'] = latlng['lng']\n",
      "        else:\n",
      "            print '  No geocode'\n",
      "        return location\n",
      "    else:\n",
      "        print '  Store not found'\n",
      "        return False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Scrape up to this store#:\n",
      "last_store = 17000\n",
      "\n",
      "# If we have previous scraped data, start where we left off.  Otherwise start at store # 1.\n",
      "starting_store = (max([location['store_number'] for location in locations]) + 1) if locations else 1\n",
      "\n",
      "for store_number in range(starting_store, last_store + 1):\n",
      "    location = scrape_store(store_number)\n",
      "    if location:\n",
      "        locations.append(location)\n",
      "        if len(locations) % 10 == 0:\n",
      "            # Checkpoint:  save all locations\n",
      "            write_locations(locations)\n",
      "\n",
      "# Done.  Save all locations\n",
      "write_locations(locations)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Trying to fetch store# 7316 from http://www.mcpennsylvania.com/7316\n",
        "  Read 16016 bytes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Address is 709 Taughenbaugh Blvd|Rifle, CO 81650\n",
        "  Geocoded to {u'lat': 39.521315, u'lng': -107.777286}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trying to fetch store# 7317 from http://www.mcpennsylvania.com/7317\n",
        "  Read 8512 bytes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Store not found\n",
        "Trying to fetch store# 7318 from http://www.mcpennsylvania.com/7318\n",
        "  Read 13783 bytes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Address is 876 Eastgate Square Blvd.|Cincinnati, OH 45245\n",
        "  Geocoded to {u'lat': 39.0937545, u'lng': -84.269781}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trying to fetch store# 7319 from http://www.mcpennsylvania.com/7319\n",
        "  Read 8512 bytes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Store not found\n",
        "Trying to fetch store# 7320 from http://www.mcpennsylvania.com/7320\n",
        "  Read 16117 bytes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Address is 2476 Kalakaua Avenue|Honolulu, HI 96815\n",
        "  Geocoded to {u'lat': 21.274685, u'lng': -157.824117}"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    }
   ],
   "metadata": {}
  }
 ]
}