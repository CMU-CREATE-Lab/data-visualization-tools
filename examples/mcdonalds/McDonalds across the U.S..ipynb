{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import json\n",
      "\n",
      "#\n",
      "# Functions to load and save scraped McDonalds locations to/from this local JSON file:\n",
      "#\n",
      "\n",
      "locations_path = os.path.expanduser('~/projects/mcdonalds/mcdonalds_locations.json')\n",
      "\n",
      "\n",
      "def read_or_create_locations():\n",
      "    try:\n",
      "        locations = json.load(open(locations_path))\n",
      "        print 'Read %d locations from %s' % (len(locations), locations_path)\n",
      "    except StandardError:\n",
      "        locations = []\n",
      "        print '%s does not exist; creating' % locations_path\n",
      "        write_locations(locations)\n",
      "    return locations\n",
      "\n",
      "def write_locations(locations):\n",
      "    try:\n",
      "        os.makedirs(os.path.dirname(locations_path))\n",
      "    except StandardError:\n",
      "        pass\n",
      "    json.dump(locations, open(locations_path + '.tmp', 'w'), indent=2)\n",
      "    os.rename(locations_path + '.tmp', locations_path)\n",
      "    print 'Wrote %d locations to %s' % (len(locations), locations_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read previously scraped locations, if any\n",
      "\n",
      "locations = read_or_create_locations()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Read 4500 locations from /Users/rsargent/projects/mcdonalds/mcdonalds_locations.json\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#\n",
      "# Functions for scraping McDonalds locations from McDonald's website, as well as geocoding\n",
      "# addresses using Google's geocoding API\n",
      "#\n",
      "\n",
      "# Things to watch out for:\n",
      "# \n",
      "# 1) If you see \"No module named scrapy.selector\", you'll need to install the scrapy library.\n",
      "#   I installed on my Mac from the commandline with \"pip install scrapy\"\n",
      "#\n",
      "# 2) If you see errors about zope.interface, try updating zope.interface to a newer version like so:\n",
      "#    \"pip install --update zope.interface\"\n",
      "#    and then restart the kernel (Kernel/Restart, at the top of the notebook, above).\n",
      "#\n",
      "# 3) Google's geolocation service is limited to around 2500 geolocations per day.  If you receive an error\n",
      "#    that you've run out of quota, you'll need to wait a day, or change your IP address.  If you don't\n",
      "#    want to wait a day, here are some ways to change your IP address:\n",
      "#    - If you're on a laptop, move to a different wireless network\n",
      "#    - Find an HTTP proxy at http://www.hidemyass.com/proxy-list and switch to that proxy with this python command:\n",
      "#      urllib2.install_opener(urllib2.build_opener(urllib2.ProxyHandler({'http': '168.63.167.183'})))\n",
      "#    - Utitlize a VPN service (e.g. Hide My Ass's \"Pro VPN\" account, which costs $)\n",
      "\n",
      "import urllib\n",
      "import urllib2\n",
      "from scrapy.selector import Selector\n",
      "\n",
      "# Take an address and find its location using Google's geocoding API\n",
      "# Returns {'lat': latitude, 'lng': longitude} on success\n",
      "# Returns False if not found\n",
      "# Raises exception if a problem occurs (such as running out of quota)\n",
      "#\n",
      "# If you run out of quota, see options in the comments above\n",
      "\n",
      "def geocode(address):\n",
      "    url = 'http://maps.googleapis.com/maps/api/geocode/json?%s' % urllib.urlencode({'address': address, 'sensor': 'false'})\n",
      "    geocode = json.loads(urllib2.urlopen(url).read())\n",
      "    if geocode['status'] == 'OK' and geocode['results']:\n",
      "        return geocode['results'][0]['geometry']['location']\n",
      "    elif geocode['status'] <> 'ZERO_RESULTS':\n",
      "        msg = 'When trying to geocode address %s by reading url %s, received a status != OK: %s' % (address, url, geocode['status'])\n",
      "        print msg\n",
      "        raise Exception(msg)\n",
      "    else:\n",
      "        return False\n",
      "\n",
      "# Scrape an individual McDonalds store #\n",
      "# Returns {'store_number': store_number, 'address': address, 'lat': latitude, 'lng': longitude} on success\n",
      "# If McDonalds website doesn't show a store by that number, return False\n",
      "# If geolocation fails, will return only 'store_number' and 'address'\n",
      "\n",
      "def scrape_store(store_number):\n",
      "    url = \"http://www.mcpennsylvania.com/%d\" % store_number\n",
      "    print \"Trying to fetch store# %d from %s\" % (store_number, url)\n",
      "    html = urllib2.urlopen(url).read()\n",
      "    print \"  Read %d bytes\" % len(html)\n",
      "    selector = Selector(text = html)\n",
      "    address = '\\n'.join(selector.xpath('//li[contains(@class, \"address\")]/h3/text()').extract())\n",
      "    if address:\n",
      "        location = {'store_number': store_number, 'address': address}\n",
      "        print '  Address is %s' % address.replace('\\n', '|')\n",
      "        latlng = geocode(address)\n",
      "        if latlng:\n",
      "            print '  Geocoded to %s' % latlng\n",
      "            location['lat'] = latlng['lat']\n",
      "            location['lng'] = latlng['lng']\n",
      "        else:\n",
      "            print '  No geocode'\n",
      "        return location\n",
      "    else:\n",
      "        print '  Store not found'\n",
      "        return False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Scrape up to this store#:\n",
      "last_store = 17000\n",
      "\n",
      "# If we have previous scraped data, start where we left off.  Otherwise start at store # 1.\n",
      "starting_store = (max([location['store_number'] for location in locations]) + 1) if locations else 1\n",
      "\n",
      "for store_number in range(starting_store, last_store + 1):\n",
      "    location = scrape_store(store_number)\n",
      "    if location:\n",
      "        locations.append(location)\n",
      "        if len(locations) % 10 == 0:\n",
      "            # Checkpoint:  save all locations\n",
      "            write_locations(locations)\n",
      "\n",
      "# Done.  Save all locations\n",
      "write_locations(locations)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Trying to fetch store# 6567 from http://www.mcpennsylvania.com/6567\n",
        "  Read 14391 bytes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Address is 1803 NW Loop 281|Longview, TX 75601\n",
        "  Geocoded to {u'lat': 32.5226002, u'lng': -94.6889954}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trying to fetch store# 6568 from http://www.mcpennsylvania.com/6568\n",
        "  Read 8512 bytes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Store not found\n",
        "Trying to fetch store# 6569 from http://www.mcpennsylvania.com/6569\n",
        "  Read 15927 bytes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Address is 2515 S. Academy Blvd|Colorado Springs, CO 80910\n",
        "  Geocoded to {u'lat': 38.795496, u'lng': -104.7569819}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trying to fetch store# 6570 from http://www.mcpennsylvania.com/6570\n",
        "  Read 16115 bytes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Address is 1703 Red Robin Ln|New Bern, NC 28560\n",
        "  Geocoded to {u'lat': 35.0999849, u'lng': -77.09207099999999}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Trying to fetch store# 6571 from http://www.mcpennsylvania.com/6571\n",
        "  Read 6543 bytes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Store not found\n",
        "Trying to fetch store# 6572 from http://www.mcpennsylvania.com/6572\n",
        "  Read 8512 bytes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Store not found\n",
        "Trying to fetch store# 6573 from http://www.mcpennsylvania.com/6573\n",
        "  Read 8512 bytes"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Store not found\n",
        "Trying to fetch store# 6574 from http://www.mcpennsylvania.com/6574\n",
        "  Read 16187 bytes"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    }
   ],
   "metadata": {}
  }
 ]
}