{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv, glob, json, os, re, shutil, subprocess, sys, urllib2\n",
    "\n",
    "def exec_ipynb(filename_or_url):\n",
    "    nb = (urllib2.urlopen(filename_or_url) if re.match(r'https?:', filename_or_url) else open(filename_or_url)).read()\n",
    "    jsonNb = json.loads(nb)\n",
    "    #check for the modified formatting of Jupyter Notebook v4\n",
    "    if(jsonNb['nbformat'] == 4):\n",
    "        exec '\\n'.join([''.join(cell['source']) for cell in jsonNb['cells'] if cell['cell_type'] == 'code']) in globals()\n",
    "    else:\n",
    "        exec '\\n'.join([''.join(cell['input']) for cell in jsonNb['worksheets'][0]['cells'] if cell['cell_type'] == 'code']) in globals()\n",
    "\n",
    "def download_file(url, filename):\n",
    "    if os.path.exists(filename):\n",
    "        sys.stdout.write('%s already downloaded\\n' % filename)\n",
    "    else:\n",
    "        if not os.path.exists(os.path.dirname(filename)):\n",
    "            os.makedirs(os.path.dirname(filename))\n",
    "        sys.stdout.write('Downloading %s to %s\\n' % (url, filename))\n",
    "        data = urllib2.urlopen(url).read()\n",
    "        open(filename + '.tmp', \"wb\").write(data)\n",
    "        os.rename(filename + '.tmp', filename)\n",
    "        sys.stdout.write('Done, wrote %d bytes to %s\\n' % (len(data), filename))\n",
    "        \n",
    "def unzip_file(filename):\n",
    "    exdir = os.path.splitext(filename)[0]\n",
    "    if os.path.exists(exdir):\n",
    "        sys.stdout.write('%s already unzipped\\n' % (filename))\n",
    "    else:\n",
    "        tmpdir = exdir + '.tmp'\n",
    "        shutil.rmtree(tmpdir, True)\n",
    "        sys.stdout.write('Unzipping %s into %s\\n' % (filename, tmpdir))\n",
    "        subprocess.check_call(['unzip', filename, '-d', tmpdir])\n",
    "        os.rename(tmpdir, exdir)\n",
    "        print 'Success, created %s' % (exdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sanitize(f):\n",
    "    return re.sub(r'\\W+', '_', f).strip('_')\n",
    "\n",
    "# print sanitize('    a b c    d')\n",
    "\n",
    "def remove_spaces(n):\n",
    "    return n.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WorldBank/EG.ELC.ACCS.ZS.zip already downloaded\n",
      "WorldBank/EG.ELC.ACCS.ZS.zip already unzipped\n",
      "Data is in WorldBank/EG.ELC.ACCS.ZS/API_EG.ELC.ACCS.ZS_DS2_en_csv_v2.csv\n"
     ]
    }
   ],
   "source": [
    "download_file('http://api.worldbank.org/v2/en/indicator/EG.ELC.ACCS.ZS?downloadformat=csv', 'WorldBank/EG.ELC.ACCS.ZS.zip')\n",
    "unzip_file('WorldBank/EG.ELC.ACCS.ZS.zip')\n",
    "files = glob.glob('WorldBank/EG.ELC.ACCS.ZS/API*csv')\n",
    "assert len(files) == 1\n",
    "file = files[0]\n",
    "print 'Data is in %s' % file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API_EG.ELC.ACCS.ZS_DS2_en_csv_v2.csv\r\n",
      "Metadata_Country_API_EG.ELC.ACCS.ZS_DS2_en_csv_v2.csv\r\n",
      "Metadata_Indicator_API_EG.ELC.ACCS.ZS_DS2_en_csv_v2.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls WorldBank/EG.ELC.ACCS.ZS\n",
    "!open WorldBank/EG.ELC.ACCS.ZS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exec_ipynb('placenames.ipynb')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "irena_csv = 'IRENA/IRENA all 2017 05 02.csv'\n",
    "reader = csv.reader(open(irena_csv))\n",
    "\n",
    "# Skip 7 rows\n",
    "for _ in range(0, 7):\n",
    "    reader.next()\n",
    "    \n",
    "# header is 8th row\n",
    "header = reader.next()\n",
    "\n",
    "# Find valid data columns\n",
    "re_yyyy = r'\\d\\d\\d\\d'\n",
    "\n",
    "technology_col = 0\n",
    "indicator_col = 1\n",
    "country_col = 2\n",
    "first_year_col = 3\n",
    "assert not re.match(re_yyyy, header[first_year_col - 1])\n",
    "assert re.match(re_yyyy, header[first_year_col])\n",
    "\n",
    "for i in range(first_year_col + 1, len(header)):\n",
    "    if not re.match(re_yyyy, header[i]):\n",
    "        last_year_col = i - 1\n",
    "        break\n",
    "\n",
    "print 'Found years %s-%s' % (header[first_year_col], header[last_year_col])\n",
    "\n",
    "current_technology = None\n",
    "csv_filename = None\n",
    "csv_file = None\n",
    "csv_nrows = 0\n",
    "\n",
    "def finish_csv():\n",
    "    global csv_nrows\n",
    "    if csv_filename:\n",
    "        csv_file.close()\n",
    "        os.rename(csv_filename + '.tmp', csv_filename)\n",
    "        print 'Created %s with %d rows' % (csv_filename, csv_nrows)\n",
    "    csv_nrows = 0\n",
    "        \n",
    "\n",
    "errors = 0\n",
    "\n",
    "for rec in reader:\n",
    "    technology = rec[technology_col]\n",
    "    indicator = rec[indicator_col]\n",
    "    country = rec[country_col]\n",
    "    if technology:\n",
    "        assert indicator\n",
    "        current_technology = technology\n",
    "    if indicator:\n",
    "        finish_csv()\n",
    "        csv_filename = 'IRENA/%s.%s.csv' % (sanitize(current_technology), sanitize(indicator))\n",
    "        csv_file = open(csv_filename + '.tmp', 'w')\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        csv_writer.writerow([''] + header[first_year_col:last_year_col+1])\n",
    "    country = canonicalize_country_name(country)\n",
    "    if not country:\n",
    "        continue\n",
    "    if country == 'Error':\n",
    "        errors += 1\n",
    "        continue\n",
    "    csv_writer.writerow([country] + [remove_spaces(x) for x in rec[first_year_col:last_year_col+1]])\n",
    "    csv_nrows += 1\n",
    "\n",
    "if errors:\n",
    "    raise Exception('Errors')\n",
    "finish_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat IRENA/Solar.Electricity_capacity_MW.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building file list ... done\n",
      "IRENA/\n",
      "IRENA/Bagasse.Electricity_capacity_MW.csv\n",
      "IRENA/Bagasse.Electricity_generation_GWh.csv\n",
      "IRENA/Bioenergy.Electricity_capacity_MW.csv\n",
      "IRENA/Bioenergy.Electricity_generation_GWh.csv\n",
      "IRENA/Biogas.Electricity_capacity_MW.csv\n",
      "IRENA/Biogas.Electricity_generation_GWh.csv\n",
      "IRENA/Concentrated_solar_power.Electricity_capacity_MW.csv\n",
      "IRENA/Concentrated_solar_power.Electricity_generation_GWh.csv\n",
      "IRENA/Hydro_10_MW.Electricity_capacity_MW.csv\n",
      "IRENA/Hydro_10_MW.Electricity_generation_GWh.csv\n",
      "IRENA/Hydro_1_10_MW.Electricity_capacity_MW.csv\n",
      "IRENA/Hydro_1_10_MW.Electricity_generation_GWh.csv\n",
      "IRENA/Hydro_1_MW.Electricity_capacity_MW.csv\n",
      "IRENA/Hydro_1_MW.Electricity_generation_GWh.csv\n",
      "IRENA/Hydropower.Electricity_capacity_MW.csv\n",
      "IRENA/Hydropower.Electricity_generation_GWh.csv\n",
      "IRENA/Liquid_biofuels.Electricity_capacity_MW.csv\n",
      "IRENA/Liquid_biofuels.Electricity_generation_GWh.csv\n",
      "IRENA/Marine.Electricity_capacity_MW.csv\n",
      "IRENA/Marine.Electricity_generation_GWh.csv\n",
      "IRENA/Mixed_plants.Electricity_capacity_MW.csv\n",
      "IRENA/Mixed_plants.Electricity_generation_GWh.csv\n",
      "IRENA/Offshore_wind_energy.Electricity_capacity_MW.csv\n",
      "IRENA/Offshore_wind_energy.Electricity_generation_GWh.csv\n",
      "IRENA/Onshore_wind_energy.Electricity_capacity_MW.csv\n",
      "IRENA/Onshore_wind_energy.Electricity_generation_GWh.csv\n",
      "IRENA/Other_solid_biofuels.Electricity_capacity_MW.csv\n",
      "IRENA/Other_solid_biofuels.Electricity_generation_GWh.csv\n",
      "IRENA/Pumped_storage.Electricity_capacity_MW.csv\n",
      "IRENA/Pumped_storage.Electricity_generation_GWh.csv\n",
      "IRENA/Renewable_municipal_waste.Electricity_capacity_MW.csv\n",
      "IRENA/Renewable_municipal_waste.Electricity_generation_GWh.csv\n",
      "IRENA/Solar.Electricity_capacity_MW.csv\n",
      "IRENA/Solar.Electricity_generation_GWh.csv\n",
      "IRENA/Solar_photovoltaic.Electricity_capacity_MW.csv\n",
      "IRENA/Solar_photovoltaic.Electricity_generation_GWh.csv\n",
      "IRENA/Solid_biofuels.Electricity_capacity_MW.csv\n",
      "IRENA/Solid_biofuels.Electricity_generation_GWh.csv\n",
      "IRENA/Total_renewable_energy.Electricity_capacity_MW.csv\n",
      "IRENA/Total_renewable_energy.Electricity_generation_GWh.csv\n",
      "IRENA/Wind.Electricity_capacity_MW.csv\n",
      "IRENA/Wind.Electricity_generation_GWh.csv\n",
      "\n",
      "sent 397826 bytes  received 4454 bytes  268186.67 bytes/sec\n",
      "total size is 1348863  speedup is 3.35\n"
     ]
    }
   ],
   "source": [
    "!rsync -av IRENA tm1:/usr4/web/data.cmucreatelab.org/www/earthtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
